# **Getting a taste of Research Papers-ðŸ’¯**

![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQzoY5RWPO4HIgxfyVnb4ZEUONYkBD7g6JOhxmnfjkGlKoAeZYSEQ)

**Repo to track my progress on New Resolution of reading, understanding and tinkering with Machine Learning Research Papers.**


|Category  |
|---       |
|[Computer Vision](#computer-vision)|
|[Convolutional Neural Networks](#convolutional-neural-networks)|
|[Federated Learning](#federated-learning)|
|[Generative Models](#generative-models)|
|[Geometric Deep Learning](#geometric-deep-learning) | 
|[Initialization And Optimization](#initialization-and-optimization) |
|[Miscellaneous](#miscellaneous)|
|[Natural Language Processing](#natural-language-processing)|
|[Reinforcement Learning](#reinforcement-learning)|


### Computer Vision
||Title|Tags|
|---|---|---|
|1.|[Panoptic Feature Pyramid Networks](https://arxiv.org/pdf/1901.02446.pdf)| 
|2.|[Attention Augmented Convolutional Networks](https://arxiv.org/pdf/1904.09925.pdf)
|3.|[Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1706.05587.pdf)
|4.|[Unsupervised Data Augmentation](https://arxiv.org/pdf/1904.12848.pdf)
|5.|[Fast AutoAugment](https://arxiv.org/pdf/1905.00397.pdf)|
|6.|[DeViSE: A Deep Visual-Semantic Embedding Model](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41473.pdf)|
|7.|[S4L: Self-Supervised Semi-Supervised Learning](https://arxiv.org/pdf/1905.03670.pdf)|
|8.|[Processing Megapixel Images with Deep Attention-Sampling Models](https://arxiv.org/pdf/1905.03711.pdf)

### Convolutional Neural Networks
||Title |Tags|
|---|---|---|
|1.|[Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/pdf/1812.01187.pdf)| 
|2.|[Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution](https://arxiv.org/pdf/1904.05049.pdf)|
|3.|[Local Relation Networks for Image Recognition](https://arxiv.org/pdf/1904.11491.pdf)|
|4.|[Invertible Residual Networks](https://arxiv.org/pdf/1811.00995.pdf)
|5.|[Kervolutional Neural Networks](https://arxiv.org/pdf/1904.03955.pdf)|
|6.|[4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks](https://arxiv.org/pdf/1904.08755.pdf)
|7.|[Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet](https://openreview.net/pdf?id=SkfMWhAqYQ)
|8.|[Making Convolutional Networks Shift-Invariant Again](https://arxiv.org/pdf/1904.11486.pdf)

### Federated Learning
||Title |Tags|
|---|---|---|
|1.|[Towards Federated Learning at Scale](https://arxiv.org/pdf/1902.01046.pdf)||
|2.|[Federated Learning for Mobile Keyboard Prediction](https://arxiv.org/pdf/1811.03604.pdf)|
|3.|[Federated Reinforcement Learning](https://arxiv.org/pdf/1901.08277.pdf)|
|4.|[Federated Learning: Strategies for Improving Communication Efficiency](https://arxiv.org/pdf/1610.05492.pdf)|
|5.|[Gaussian Differential Privacy](https://arxiv.org/pdf/1905.02383.pdf)|

### Generative Models
||Title|Tags|
|---|---|---|
|1.|[A Style-Based Generator Architecture for Generative Adversarial Networks ](https://arxiv.org/pdf/1812.04948.pdf)|
|2.|[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/pdf/1511.06434.pdf)
|3.|[Controllable Artistic Text Style Transfer via Shape-Matching GAN](https://arxiv.org/pdf/1905.01354.pdf)|
|4.|[SinGAN: Learning a Generative Model from a Single Natural Image](https://arxiv.org/pdf/1905.01164.pdf)|
|5.|[Sketchforme: Composing Sketched Scenes from Text Descriptions for Interactive Applications](https://arxiv.org/pdf/1904.04399.pdf)|
|6.|[Few-Shot Unsupervised Image-to-Image Translation](https://arxiv.org/pdf/1905.01723.pdf)
|7.|[Semantic Image Synthesis with Spatially-Adaptive Normalization](https://arxiv.org/pdf/1903.07291.pdf)

### Deep Learning on Graphs
||Title|Tags|
|---|---|---|
|1.|[Deep Learning on Graphs : A Survey](https://arxiv.org/abs/1812.04202)    |  
|2.|[Graph Neural Networks: A Review of Methods and Applications](https://arxiv.org/abs/1812.08434)    |	  
|3.|[A Comprehensive Survey on Graph Neural Networks](https://arxiv.org/abs/1901.00596)    |	 
|4.|[Graph Matching Networks for Learning the Similarity of Graph Structured Objects](https://arxiv.org/pdf/1904.12787.pdf)|

### Initialization And Optimization
||Title|Tags|
|---|---|---|
|1.|[Fixup Initialization: Residual Learning Without Normalization](https://arxiv.org/pdf/1901.09321.pdf)|
|2.|[A disciplined approach to neural network hyper-parameters: Part 1 -- learning rate, batch size, momentum, and weight decay](https://arxiv.org/pdf/1803.09820.pdf)
|3.|[L4: Practical loss-based stepsize adaptation for deep learning](https://arxiv.org/pdf/1802.05074.pdf)|
|4.|[A Mean Field Theory of Batch Normalization](https://arxiv.org/pdf/1902.08129.pdf)
|5.|[The Lottery Ticket Hypothesis:Finding Sparse,Trainable Neural Networks](https://arxiv.org/pdf/1803.03635.pdf)|
|6.|[Deconstructing Lottery Tickets: Zeros, Signs, and the Supermask](https://arxiv.org/pdf/1905.01067.pdf)|
|7.|[The Lottery Ticket Hypothesis at Scale](https://arxiv.org/pdf/1903.01611.pdf)|
|8.|[REGAL: Transfer Learning For Fast Optimization of Computation Graphs](https://arxiv.org/pdf/1905.02494.pdf)

### Miscellaneous
||Title|Tags|
|---|---|---|
|1.|[EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Task](https://arxiv.org/pdf/1901.11196.pdf)|
|2.|[Attentive Neural Processes](https://arxiv.org/pdf/1901.05761.pdf)|
|3.|[TensorLy: Tensor Learning in Python](https://arxiv.org/pdf/1610.09555.pdf)|
|4.|[Meta-Sim: Learning to Generate Synthetic Datasets](https://arxiv.org/pdf/1904.11621.pdf)|
|5.|[Low-Memory Neural Network Training: A Technical Report](https://arxiv.org/pdf/1904.10631.pdf)|
|6.|[Using Deep Learning to Annotate the Protein Universe](https://www.biorxiv.org/content/biorxiv/early/2019/05/04/626507.full.pdf)|
|7.|[Initialized Equilibrium Propagation for Backprop-Free Training](https://openreview.net/pdf?id=B1GMDsR5tm)
|8.|[MixMatch: A Holistic Approach to Semi-Supervised Learning](https://arxiv.org/pdf/1905.02249.pdf)|
|9.|[Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/pdf/1905.02175.pdf)
|10.|[Style Transfer by Relaxed Optimal Transport and Self-Similarity](https://arxiv.org/pdf/1904.12785.pdf)

### Natural Language Processing
||Title  |Tags|
|--- |---     |---|
|1.|[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://paperswithcode.com/paper/bert-pre-training-of-deep-bidirectional2)|
|2.|[Parameter-Efficient Transfer Learning for NLP](https://arxiv.org/pdf/1902.00751.pdf)|
|3.|[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)|
|4.|[Visualizing Attention in Transformer-Based Language Representation Models](https://arxiv.org/pdf/1904.02679.pdf)|
|5.|[Language Models with Transformers](https://arxiv.org/pdf/1904.09408.pdf)
|6.|[Generating Long Sequences with Sparse Transformers](https://d4mucfpksywv.cloudfront.net/Sparse_Transformer/sparse_transformers.pdf)
|7.|[Neural Networks for Modeling Source Code Edits](https://arxiv.org/pdf/1904.02818.pdf)
|8.|[Sample Efficient Adaptive Text-to-Speech](https://openreview.net/pdf?id=rkzjUoAcFX)
|9.|[Unified Language Model Pre-training for Natural Language Understanding and Generation](https://arxiv.org/pdf/1905.03197.pdf)

### Reinforcement Learning
||Title|Tags|
|---|---|---|
|1.   |[Scalable agent alignment via reward modeling: a research direction](https://arxiv.org/pdf/1811.07871) | 
|2.|[Reinforcement Learning with Attention that Works: A Self-Supervised Approach](https://arxiv.org/pdf/1904.03367.pdf)|
|3.|[Challenges of Real-World Reinforcement Learning](https://arxiv.org/pdf/1904.12901.pdf)|
|4.|[An Introduction to Deep Reinforcement Learning](https://arxiv.org/pdf/1811.12560.pdf)|
